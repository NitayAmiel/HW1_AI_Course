{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NitayAmiel/HW_AI_Course/blob/main/HW6_AI_course_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYxTM1X5CtXQ"
      },
      "source": [
        "# Set up\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDbpD8-DCU6K",
        "outputId": "0af0a2db-9554-4a47-e2d9-a4da2a0553e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75kKGEedCxi6",
        "outputId": "5c7c97fd-e4e8-4be7-d022-f4f3e2b543ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1--E2a3ior8D_isWan7ePmd_NmsNcy6Uk/drone_data\n"
          ]
        }
      ],
      "source": [
        "HOME = \"/content/drive/MyDrive/testing123/drone_data\"\n",
        "\n",
        "# NOTICE: Adjust the path above accordingly to your files' location\n",
        "\n",
        "%cd {HOME}\n",
        "\n",
        "BIRD_PATH = '/content/drive/MyDrive/testing123/bird_data'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4WoOPFQCssN"
      },
      "source": [
        "# **Preproccessing the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IX6EeYxOUWo"
      },
      "source": [
        "# augmentations functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7O0pumlKOTU0"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def random_flip(image):\n",
        "    return ImageOps.mirror(image)\n",
        "\n",
        "def color_jitter(image, brightness_factor=0.2, contrast_factor=0.2, saturation_factor=0.2):\n",
        "    enhancer = ImageEnhance.Brightness(image)\n",
        "    image = enhancer.enhance(1 + random.uniform(-brightness_factor, brightness_factor))\n",
        "\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(1 + random.uniform(-contrast_factor, contrast_factor))\n",
        "\n",
        "    enhancer = ImageEnhance.Color(image)\n",
        "    image = enhancer.enhance(1 + random.uniform(-saturation_factor, saturation_factor))\n",
        "\n",
        "    return image\n",
        "\n",
        "def random_rotation(image, max_angle=45):\n",
        "    angle = random.uniform(-max_angle, max_angle)\n",
        "    return image.rotate(angle)\n",
        "\n",
        "augmentations = [random_flip, color_jitter, random_rotation]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_image(img, title):\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(img)\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "e85Fm80qrFw_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sESWiJkLGz6"
      },
      "source": [
        "first we will generate random images and drone images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nctv0TLOEC3Y",
        "outputId": "d84a3117-0e6e-4998-b746-20955e793dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " index = 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "OTHER = 0\n",
        "DRONE = 1\n",
        "BIRD = 2\n",
        "\n",
        "# Seperating between the images and the annotations\n",
        "images = [image for image in os.listdir(HOME) if image[image.rfind(\".\")+1:] == \"jpg\"]\n",
        "labels = [label for label in os.listdir(HOME) if label[label.rfind(\".\")+1:] == \"txt\"]\n",
        "\n",
        "drone_images = []\n",
        "other_images =[]\n",
        "\n",
        "for index,label in enumerate(labels):\n",
        "  if index == 10:\n",
        "    break\n",
        "  # Just for following the runtime (running this cell takes 2 minutes approx.)\n",
        "  if index % 10 == 0:\n",
        "    print(f' {index = }')\n",
        "\n",
        "  # Reading the coordinates from the annotations, Remember: the labels are as YOLO V8 format.\n",
        "  with open(label) as label_file:\n",
        "    content = label_file.read()\n",
        "    lst = content.split(\" \")\n",
        "    lst[4] = lst[4][:-1] #removing \\n\n",
        "    x_center, y_center, width, height = float(lst[1]), float(lst[2]),float(lst[3]),float(lst[4])\n",
        "\n",
        "    # The coordinates list is in this order : x_left, y_top, x_right, y_down\n",
        "    coordinates = [x_center - width/2, y_center - height/2 ,x_center + width/2, y_center + height/2]\n",
        "    image_drone = Image.open(images[index])\n",
        "    pixels_width, pixels_height = image_drone.size\n",
        "\n",
        "    # Represnting the coordinates as number of pixels, and not as float in [0,1]\n",
        "    for i in range(4):\n",
        "      coordinates[i] = int(coordinates[i]*pixels_width) if i%2 == 0 else int(coordinates[i]*pixels_height)\n",
        "\n",
        "    # Cropping , converting to gray, reshaping, and then saving the binding box with respect lebel( a drone)\n",
        "    bnbox = image_drone.crop(tuple(coordinates))\n",
        "    box = bnbox.resize((32,32))\n",
        "    box = image.img_to_array(box, dtype = np.uint8)\n",
        "    reshaped_img_array = np.reshape(box, (32,32,3))\n",
        "    drone_images.append((reshaped_img_array, DRONE))\n",
        "\n",
        "    # apllying augmentation and append\n",
        "    changed_image = augmentations[random.randint(0,2)](bnbox)\n",
        "    changed_image = changed_image.resize((32,32))\n",
        "    changed_image = image.img_to_array(changed_image, dtype = np.uint8)\n",
        "    reshaped_img_array = np.reshape(changed_image, (32,32,3))\n",
        "    drone_images.append((reshaped_img_array, DRONE))\n",
        "\n",
        "\n",
        "    # Creating a random 28*28 picture, converting it to gray, reshaping it, and then saving with respect lebel(not a drone)\n",
        "    x_random = random.randint(0,pixels_width-32)\n",
        "    y_random = random.randint(0,pixels_height-32)\n",
        "    not_drone_image = image_drone.crop((x_random, y_random,x_random+32, y_random+32 ))\n",
        "    not_drone_image = image.img_to_array(not_drone_image, dtype = np.uint8)\n",
        "    not_drone_image = np.reshape(not_drone_image, (32,32,3))\n",
        "    other_images.append((not_drone_image, OTHER))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znFwTMkXLNDu"
      },
      "source": [
        "extracting the bird images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcwWoyvIL3IB",
        "outputId": "192d432c-9b6c-435d-a2a8-4ef9b8b55065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1YTpCrZXrygq52NizdbEjLGw_TI4tbGyy/bird_data\n"
          ]
        }
      ],
      "source": [
        "%cd {BIRD_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDf5TrXCLEXW",
        "outputId": "e8631412-f521-4359-ec8d-ee2ef7db92ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " index = 0\n"
          ]
        }
      ],
      "source": [
        "images = [image for image in os.listdir(BIRD_PATH) if image[image.rfind(\".\")+1:] == \"jpg\"]\n",
        "labels = [label for label in os.listdir(BIRD_PATH) if label[label.rfind(\".\")+1:] == \"txt\"]\n",
        "\n",
        "bird_images = []\n",
        "\n",
        "for index,label in enumerate(labels):\n",
        "  if index == 10:\n",
        "    break\n",
        "  # Just for following the runtime (running this cell takes 2 minutes approx.)\n",
        "  if index % 10 == 0:\n",
        "    print(f' {index = }')\n",
        "\n",
        "  # Reading the coordinates from the annotations, Remember: the labels are as YOLO V8 format.\n",
        "  with open(label) as label_file:\n",
        "    content = label_file.read()\n",
        "    lst = content.split(\" \")\n",
        "    lst[4] = lst[4][:-1] #removing \\n\n",
        "    x_center, y_center, width, height = float(lst[1]), float(lst[2]),float(lst[3]),float(lst[4])\n",
        "\n",
        "    # The coordinates list is in this order : x_left, y_top, x_right, y_down\n",
        "    coordinates = [x_center - width/2, y_center - height/2 ,x_center + width/2, y_center + height/2]\n",
        "    image_bird = Image.open(images[index])\n",
        "    pixels_width, pixels_height = image_bird.size\n",
        "\n",
        "    # Represnting the coordinates as number of pixels, and not as float in [0,1]\n",
        "    for i in range(4):\n",
        "      coordinates[i] = int(coordinates[i]*pixels_width) if i%2 == 0 else int(coordinates[i]*pixels_height)\n",
        "\n",
        "    # Cropping , converting to gray, reshaping, and then saving the binding box with respect lebel( a drone)\n",
        "    bnbox = image_bird.crop(tuple(coordinates))\n",
        "    box = bnbox.resize((32,32))\n",
        "    box = image.img_to_array(box, dtype = np.uint8)\n",
        "    reshaped_img_array = np.reshape(box, (32,32,3))\n",
        "    bird_images.append((reshaped_img_array, DRONE))\n",
        "\n",
        "    # apllying augmentation and append\n",
        "    changed_image = augmentations[random.randint(0,2)](bnbox)\n",
        "    changed_image = changed_image.resize((32,32))\n",
        "    changed_image = image.img_to_array(changed_image, dtype = np.uint8)\n",
        "    reshaped_img_array = np.reshape(changed_image, (32,32,3))\n",
        "    bird_images.append((reshaped_img_array, BIRD))\n",
        "\n",
        "\n",
        "    # Creating a random 28*28 picture, converting it to gray, reshaping it, and then saving with respect lebel(not a drone)\n",
        "    x_random = random.randint(0,pixels_width-32)\n",
        "    y_random = random.randint(0,pixels_height-32)\n",
        "    not_bird_image = image_bird.crop((x_random, y_random,x_random+32, y_random+32 ))\n",
        "    not_bird_image = image.img_to_array(not_bird_image, dtype = np.uint8)\n",
        "    not_bird_image = np.reshape(not_bird_image, (32,32,3))\n",
        "    other_images.append((not_bird_image, OTHER))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqRKjQ1AMyIm"
      },
      "source": [
        "**Applying augmentations like random flip, color jitter, and rotation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8gZMCPVMxyl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SxxnUWpMMwH"
      },
      "source": [
        "displaying some images from the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP8djcU0Yj-3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Write here how many pictures you wish to display from every data set\n",
        "number_of_images_to_display = 20\n",
        "\n",
        "counter = 0\n",
        "for img in drone_images:\n",
        "  title = \"original drone\" if counter %2 == 0 else \"drone after augmentation\"\n",
        "  display_image(img[0], title)\n",
        "  counter += 1\n",
        "  if counter > number_of_images_to_display:\n",
        "    break\n",
        "\n",
        "\n",
        "counter = 0\n",
        "for img in bird_images:\n",
        "  title = \"original bird\" if counter %2 == 0 else \"bird after augmentation\"\n",
        "  display_image(img[0], title)\n",
        "  counter += 1\n",
        "  if counter > number_of_images_to_display:\n",
        "    break\n",
        "\n",
        "\n",
        "counter = 0\n",
        "for img in other_images:\n",
        "  display_image(img[0], \"other\")\n",
        "  counter += 1\n",
        "  if counter > number_of_images_to_display:\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIF8pTIfk6q5"
      },
      "source": [
        "# converting to TensorFlow Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al3sHqiTk_Uf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Adjust by your choice, to how to seperate the data (train and test)\n",
        "split_ratio = 0.85\n",
        "\n",
        "data_list = drone_images + other_images + bird_images\n",
        "random.shuffle(data_list)\n",
        "split_point = int(len(data_list)*split_ratio)\n",
        "train_list = data_list[:split_point]\n",
        "test_list = data_list[split_point:]\n",
        "\n",
        "\n",
        "# Function to create a generator\n",
        "def data_generator(list_of_data):\n",
        "    for image_array, label in list_of_data:\n",
        "        yield image_array, label\n",
        "\n",
        "# Define the types and shapes of the elements in each tuple\n",
        "element_spec = (\n",
        "    tf.TensorSpec(shape=(32, 32, 3), dtype=tf.float32),\n",
        "    tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        ")\n",
        "\n",
        "# Create the TensorFlow dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda : data_generator(train_list), output_signature=element_spec)\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda : data_generator(test_list), output_signature=element_spec)\n",
        "\n",
        "\n",
        "# Preprocess the data, it might take a while\n",
        "train_images = np.array([img[0]  for img in train_dataset], dtype=np.float32)\n",
        "test_images = np.array([img[0]  for img in test_dataset], dtype=np.float32)\n",
        "train_labels = np.array([img[1]  for img in train_dataset], dtype=np.int32)\n",
        "test_labels = np.array([img[1]  for img in test_dataset],dtype=np.int32)\n",
        "\n",
        "# Converting the pixels to number in [0,1]\n",
        "train_images = train_images.reshape((len(train_images), 32, 32, 3)).astype('float32') / 255\n",
        "test_images = test_images.reshape((len(test_images), 32, 32, 3)).astype('float32') / 255\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zD1MSor4ej1"
      },
      "source": [
        "**size of data set**\n",
        "\n",
        " the data is perfectly balnced, 50% drones and 50% not\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exCyT8ISQrre",
        "outputId": "adaa807a-7555-4417-e3ad-e9f0647761bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8140\n"
          ]
        }
      ],
      "source": [
        "print(len(data_list)) # the size of the entire data(including the random pictures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQpwl90GQQ5e"
      },
      "source": [
        "# creting a model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piqfhG63QWd3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Create the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layer 1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional layer 2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional layer 3\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output and add fully connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer with 3 neurons (3 categories)\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Display a summary of the model architecture, uneccessery - you can write it as a comment\n",
        "model.summary()\n",
        "\n",
        "# Defining the batch and the epochs\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycsS-Wtr4Gio"
      },
      "source": [
        "**evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA1v62DG4FzH"
      },
      "outputs": [],
      "source": [
        "#Evaluate the model on a test dataset if available\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INFxQ_EO4VKn"
      },
      "source": [
        "**example of prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJMzA6aN4Sta"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "number_of_pictures_to_predict = 20\n",
        "\n",
        "new_data = test_images[: number_of_pictures_to_predict]\n",
        "\n",
        "predictions = model.predict(new_data)\n",
        "\n",
        "# Convert predictions to binary (0 or 1) based on a threshold (e.g., 0.5), you can adjust for more or less surency\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "counter = 0\n",
        "# Plot the images along with their predictions\n",
        "for i in range(len(new_data)):\n",
        "    plt.imshow(new_data[i].reshape(28, 28), cmap='gray')\n",
        "    real = \"It is a drone\" if test_labels[i] == DRONE else \"It is NOT a drone\"\n",
        "    predict = \"It is a drone\" if binary_predictions[i][0] == DRONE else \"It is NOT a drone\"\n",
        "    if real == predict:\n",
        "      counter += 1\n",
        "    plt.title(f'Prediction: {predict},  real Answer: {real}')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"In summary we have {counter} good predictions, out from {number_of_pictures_to_predict}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oidGbLa5qgrvaHYCC4TAhaui-aHDk49A",
      "authorship_tag": "ABX9TyOJHoQJFMylbkiiLkT+GWI6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}